{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebfd185e-d283-4b6b-92dc-3401ae8eef9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.ones(4, requires_grad =True)\n",
    "weights = 3.0\n",
    "\n",
    "z = weights * x\n",
    "\n",
    "z = z.sum()\n",
    "\n",
    "z.backward()\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13888b57-570c-436f-a30b-1cf788849672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(64.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(4.0)\n",
    "y = torch.tensor(8.0)\n",
    "\n",
    "weights = torch.tensor(4.0, requires_grad = True)\n",
    "\n",
    "y_pred = weights * x\n",
    "\n",
    "loss = (y_pred - y) ** 2\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print(weights.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a1850cb-0d71-4a95-96f4-2ae31302b7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the prediction before training: f(5) = 15.000\n",
      "epoch 1: w = 2.040, loss = 83.333\n",
      "epoch 3: w = 1.420, loss = 3.371\n",
      "epoch 5: w = 1.296, loss = 0.188\n",
      "epoch 7: w = 1.271, loss = 0.061\n",
      "epoch 9: w = 1.266, loss = 0.056\n",
      "epoch 11: w = 1.265, loss = 0.056\n",
      "epoch 13: w = 1.265, loss = 0.056\n",
      "epoch 15: w = 1.265, loss = 0.056\n",
      "epoch 17: w = 1.265, loss = 0.056\n",
      "epoch 19: w = 1.265, loss = 0.056\n",
      "epoch 21: w = 1.265, loss = 0.056\n",
      "epoch 23: w = 1.265, loss = 0.056\n",
      "epoch 25: w = 1.265, loss = 0.056\n",
      "epoch 27: w = 1.265, loss = 0.056\n",
      "epoch 29: w = 1.265, loss = 0.056\n",
      "epoch 31: w = 1.265, loss = 0.056\n",
      "epoch 33: w = 1.265, loss = 0.056\n",
      "epoch 35: w = 1.265, loss = 0.056\n",
      "epoch 37: w = 1.265, loss = 0.056\n",
      "epoch 39: w = 1.265, loss = 0.056\n",
      "epoch 41: w = 1.265, loss = 0.056\n",
      "epoch 43: w = 1.265, loss = 0.056\n",
      "epoch 45: w = 1.265, loss = 0.056\n",
      "epoch 47: w = 1.265, loss = 0.056\n",
      "epoch 49: w = 1.265, loss = 0.056\n",
      "the prediction after training: f(5) = 6.325\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([3, 5, 7], dtype = torch.float32)\n",
    "y = torch.tensor([4, 6, 9], dtype = torch.float32)\n",
    "w = torch.tensor(3.0, dtype = torch.float32, requires_grad = True)\n",
    "\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "def loss(y_pred, y):\n",
    "    return((y_pred - y)**2).mean()\n",
    "\n",
    "print(f\"the prediction before training: f(5) = {forward(5).item():.3f}\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "n_iters = 50\n",
    "\n",
    "for epochs in range(n_iters):\n",
    "     y_pred = forward(x)\n",
    "     l = loss (y_pred , y)\n",
    "\n",
    "     l.backward()\n",
    "\n",
    "     with torch.no_grad():\n",
    "        \n",
    "          w -= learning_rate * w.grad\n",
    "        \n",
    "     w.grad.zero_()\n",
    "\n",
    "     if epochs % 2 == 0:\n",
    "         print(f\"epoch {epochs + 1}: w = {w.item():.3f}, loss = {l.item():.3f}\")\n",
    "         \n",
    "print(f\"the prediction after training: f(5) = {forward(5):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f991a1f-bb40-4866-851b-c37a02378865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the prediction before training: f(5) = 15.000\n",
      "epoch 1: w = 2.040, loss = 83.333\n",
      "epoch 11: w = 1.265, loss = 0.056\n",
      "epoch 21: w = 1.265, loss = 0.056\n",
      "epoch 31: w = 1.265, loss = 0.056\n",
      "epoch 41: w = 1.265, loss = 0.056\n",
      "the prediction after training: f(5) = 6.325\n",
      "Final learned w: 1.265060305595398\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([3, 5, 7], dtype=torch.float32)\n",
    "y = torch.tensor([4, 6, 9], dtype=torch.float32)\n",
    "w = torch.tensor(3.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "def loss(y_pred, y):\n",
    "    return ((y_pred - y)**2).mean()\n",
    "\n",
    "print(f\"the prediction before training: f(5) = {forward(5.0).item():.3f}\")\n",
    "\n",
    "learning_rate = 0.01   # <-- must reduce LR for multi-sample gradient\n",
    "n_iters = 50\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    y_pred = forward(x)\n",
    "    l = loss(y_pred, y)\n",
    "\n",
    "    l.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "\n",
    "    w.grad.zero_()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.3f}\")\n",
    "\n",
    "print(f\"the prediction after training: f(5) = {forward(5.0).item():.3f}\")\n",
    "print(\"Final learned w:\", w.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a1da17b-622f-4fbb-a307-c45b7996b76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the prediction before training: f(5) = 15.000\n",
      " the prediction after training: f(5) = 11.267\n",
      " the prediction after training: f(5) = 9.375\n",
      " the prediction after training: f(5) = 8.417\n",
      " the prediction after training: f(5) = 7.931\n",
      " the prediction after training: f(5) = 7.685\n",
      " the prediction after training: f(5) = 7.560\n",
      " the prediction after training: f(5) = 7.497\n",
      " the prediction after training: f(5) = 7.465\n",
      " the prediction after training: f(5) = 7.449\n",
      " the prediction after training: f(5) = 7.441\n",
      " the prediction after training: f(5) = 7.437\n",
      " the prediction after training: f(5) = 7.435\n",
      " the prediction after training: f(5) = 7.434\n",
      " the prediction after training: f(5) = 7.433\n",
      " the prediction after training: f(5) = 7.433\n",
      " the prediction after training: f(5) = 7.433\n",
      " the prediction after training: f(5) = 7.433\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n",
      " the prediction after training: f(5) = 7.432\n"
     ]
    }
   ],
   "source": [
    "import torch    \n",
    "\n",
    "x = torch.tensor([3, 4, 7], dtype = torch.float32)\n",
    "y = torch.tensor([5,8,9], dtype = torch.float32)\n",
    "\n",
    "w  = torch.tensor(3.0, dtype = torch.float32, requires_grad = True)\n",
    "\n",
    "\n",
    "def foward(x):\n",
    "    return w* X\n",
    "\n",
    "def loss(y_pred, y):\n",
    "    return((y_pred - y)**2).mean()\n",
    "\n",
    "print(f\" the prediction before training: f(5) = {forward(5.0):.3f}\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_iters = 50\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    y_pred = forward(x)\n",
    "    l = loss(y_pred, y)\n",
    "\n",
    "    l.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad \n",
    "\n",
    "        w.grad.zero_()\n",
    "\n",
    "    if epochs % 5 == 0:\n",
    "        print(f\"epoch{epoch+1}: w = {w:.3f}, loss = {l:.8f}\")\n",
    "\n",
    "    print(f\" the prediction after training: f(5) = {forward(5.0):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18d978d8-083f-43e5-9fe6-622131420cc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<string>, line 43)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<string>:43\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(f\"the prediction before the training : f(5) = {model(weight).item():.3f}\")\u001b[0m\n\u001b[1;37m                                                                                    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "x = torch.tensor([[3], [4], [7], [3]])\n",
    "y = torch.tensor([[7], [3], [2], [9]])\n",
    "\n",
    "\n",
    "n_samples, n_features = x.shape\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "model = nn.Linear(input_size, output_size)\n",
    "weight = torch.tensor([[5.0]], dtype = torch.float32, requires_grad = True)\n",
    "\n",
    "print(f\"the prediction before the training: f(5) = {forward(weight).item():.7f}\")\n",
    "\n",
    "# training loop\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    \n",
    "    y_pred = model(x)\n",
    "\n",
    "    l = loss(y_pred, y)\n",
    "\n",
    "    l.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        w, b =  model.parameters()\n",
    "        \n",
    "\n",
    "        print(f\"epoch{epoch+1}: w = {w[0][0].item():.3f}, loss = {l:.6f}\")\n",
    "\n",
    " print(f\"the prediction before the training : f(5) = {model(weight).item():.3f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67d658dd-9420-4a88-a212-0710dc443ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the prediction before the training : f(5) = 5.428\n",
      "epoch 1, w = 0.912, loss = 18.734821\n",
      "epoch 11, w = 0.758, loss = 17.300346\n",
      "epoch 21, w = 0.704, loss = 16.595287\n",
      "epoch 31, w = 0.652, loss = 15.924471\n",
      "epoch 41, w = 0.601, loss = 15.286223\n",
      "epoch 51, w = 0.551, loss = 14.678965\n",
      "epoch 61, w = 0.503, loss = 14.101190\n",
      "epoch 71, w = 0.456, loss = 13.551468\n",
      "epoch 81, w = 0.410, loss = 13.028437\n",
      "epoch 91, w = 0.365, loss = 12.530800\n",
      "\n",
      "prediction AFTER training : f(5) = 4.442\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Training data\n",
    "x = torch.tensor([[3.0], [4.0], [7.0], [3.0]])\n",
    "y = torch.tensor([[7.0], [3.0], [2.0], [9.0]])\n",
    "\n",
    "n_samples, n_features = x.shape\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "# Model\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# Before training prediction\n",
    "test_value = torch.tensor([[5.0]])\n",
    "print(f\"the prediction before the training : f(5) = {model(test_value).item():.3f}\")\n",
    "\n",
    "# Loss and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "n_iters = 100\n",
    "for epoch in range(n_iters):\n",
    "\n",
    "    # Forward pass\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute loss\n",
    "    l = loss_fn(y_pred, y)\n",
    "\n",
    "    # Backward pass\n",
    "    l.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # Zero gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        w, b = model.parameters()\n",
    "        print(f\"epoch {epoch+1}, w = {w.item():.3f}, loss = {l.item():.6f}\")\n",
    "\n",
    "# After training\n",
    "print(f\"\\nprediction AFTER training : f(5) = {model(test_value).item():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8d36d9b-6b14-42e3-a710-0b682ceebd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the prediction before the training: f(5) = 20.0000\n",
      "epoch 1: w = 1.920, loss = 80.33333587646484\n",
      "epoch 11: w = 1.689, loss = 0.21481485664844513\n",
      "epoch 21: w = 1.689, loss = 0.21481485664844513\n",
      "epoch 31: w = 1.689, loss = 0.21481485664844513\n",
      "epoch 41: w = 1.689, loss = 0.21481485664844513\n",
      "the prediction after the training : f(5) = 8.44444466\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "x = torch.tensor([2, 4, 5], dtype = torch.float32)\n",
    "y = torch.tensor([4, 7, 8], dtype = torch.float32)\n",
    "\n",
    "weight = torch.tensor([4], dtype = torch.float32, requires_grad = True)\n",
    "\n",
    "def forward(x):\n",
    "    return weight * x\n",
    "\n",
    "print(f\"the prediction before the training: f(5) = {forward(5.0).item():.4f}\")\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "learning_rate = 0.03\n",
    "n_iters = 50\n",
    "\n",
    "optimizer = optim.SGD([weight], lr = learning_rate)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    y_pred = forward(x)\n",
    "\n",
    "    l = loss(y_pred, y)\n",
    "\n",
    "    l.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10 ==0:\n",
    "       print(f\"epoch {epoch+1}: w = {weight.item():.3f}, loss = {l.item():}\")\n",
    "\n",
    "print(f\"the prediction after the training : f(5) = {forward(5.0).item():.8f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f06c512e-0129-40b1-b770-35dbe22a636a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the prediction before the training: f(5) = 25.0000\n",
      "epoch1:, w = 3.5540, loss = 762.50000000\n",
      "epoch11:, w = 0.8824, loss = 11.59733677\n",
      "epoch21:, w = 0.8453, loss = 11.45261383\n",
      "epoch31:, w = 0.8448, loss = 11.45258617\n",
      "epoch41:, w = 0.8448, loss = 11.45258617\n",
      " the prediction after the training : f(5) = 4.224138\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "x = torch.tensor([2, 5, 8, 9], dtype = torch.float32)\n",
    "y = torch.tensor([4, 8, 9, 3], dtype = torch.float32)\n",
    "\n",
    "w = torch.tensor([5.0], dtype = torch.float32, requires_grad = True)\n",
    "\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "print(f\"the prediction before the training: f(5) = {forward(5.0).item():.4f}\")\n",
    "\n",
    "learning_rate = 0.004\n",
    "n_iters = 50\n",
    "\n",
    "optimizer = optim.SGD([w], lr = learning_rate)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "\n",
    "    y_pred = forward(x)\n",
    "\n",
    "    l = loss(y_pred, y)\n",
    "\n",
    "    l.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"epoch{epoch+1}:, w = {w.item():.4f}, loss = {l.item():.8f}\")\n",
    "\n",
    "print(f\" the prediction after the training : f(5) = {forward(5.0).item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2757e8d0-da4e-42d5-8014-0b7b643b7a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the epoch1: loss = l5701.9047852\n",
      " the epoch11: loss = l4226.5244141\n",
      " the epoch21: loss = l3159.0747070\n",
      " the epoch31: loss = l2385.9394531\n",
      " the epoch41: loss = l1825.4141846\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "X_numpy, Y_numpy = datasets.make_regression(n_samples = 100, n_features = 1, noise = 20, random_state = 1)\n",
    "\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "Y = torch.from_numpy(Y_numpy.astype(np.float32))\n",
    "\n",
    "y = Y.view(Y.shape[0],1)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_iters = 50\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "\n",
    "    y_pred = model(X)\n",
    "\n",
    "    l = criterion(y_pred, y)\n",
    "\n",
    "    l.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\" the epoch{epoch+1}: loss = l{l.item():.7f}\")\n",
    "\n",
    "\n",
    "\n",
    "predicted = model(X).detach()\n",
    "\n",
    "plt.plot(X_numpy, Y_numpy, 'ro')\n",
    "plt.plot(X_numpy, predicted, 'b')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8642b565-c37a-47b1-bf1e-dec330b70058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569 30\n",
      "epoch10, loss = 0.5194\n",
      "epoch20, loss = 0.4290\n",
      "epoch30, loss = 0.3715\n",
      "epoch40, loss = 0.3315\n",
      "epoch50, loss = 0.3021\n",
      "epoch60, loss = 0.2794\n",
      "epoch70, loss = 0.2613\n",
      "epoch80, loss = 0.2465\n",
      "epoch90, loss = 0.2341\n",
      "epoch100, loss = 0.2236\n",
      "accuracy = 0.9211\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# prepare the data\n",
    "\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1234)\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "x_train = torch.from_numpy(x_train.astype(np.float32))\n",
    "x_test = torch.from_numpy (x_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "\n",
    "\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        y_pred = torch.sigmoid(self.linear(X))\n",
    "        return y_pred\n",
    "\n",
    "learning_rate = 0.01\n",
    "model = LogisticRegression(n_features)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "n_iters = 100\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    y_pred = model(x_train)\n",
    "\n",
    "    loss = criterion(y_pred, y_train)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "         print(f\"epoch{epoch+1}, loss = {loss.item():.4f}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model(x_test)\n",
    "    y_pred_cls = y_pred.round()\n",
    "    accuracy = y_pred_cls.eq(y_test).sum()/float(y_test.shape[0])\n",
    "    print(f\"accuracy = {accuracy:.4f}\")\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "365acd07-61a4-4eb7-8deb-d54c099d2618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss1 numpy:0.3567\n",
      "Loss2 numpy:1.20397\n"
     ]
    }
   ],
   "source": [
    "# softmax calculation and CrossEntropyLoss\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "def cross_entropy(actual, predicted):\n",
    "    loss = -np.sum(actual * np.log(predicted))\n",
    "    return loss\n",
    "\n",
    "Y = np.array([1,0,0])\n",
    "\n",
    "y_pred_good = np.array([0.7, 0.2, 0.1])\n",
    "y_pred_poor = np.array([0.3, 0.3, 0.1])\n",
    "\n",
    "l2 = cross_entropy(Y, y_pred_good)\n",
    "l3 = cross_entropy(Y, y_pred_poor)\n",
    "\n",
    "print(f\"Loss1 numpy:{l2:.4f}\")\n",
    "print(f\"Loss2 numpy:{l3:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a764a5e1-2e95-419b-8b0c-22f7b67f4459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4170299470424652\n",
      "1.840616226196289\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "Y = torch.tensor([0])\n",
    "y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
    "y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
    "\n",
    "l1 = loss(y_pred_good, Y)\n",
    "l2 = loss(y_pred_bad, Y)\n",
    "\n",
    "print(l1.item())\n",
    "print(l2.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49a7e34e-e003-467a-b42b-9b7d1d2ee0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear = (input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid\n",
    "\n",
    "    def foward(self, x):\n",
    "        out = torch.linear(x)\n",
    "        out = torch.relu(out)\n",
    "        out = torch.linear2(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9170e486-71ad-44db-8e53-157709e002ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 5., 8., 9.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F \n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, out):\n",
    "        out = self.linear1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        return out\n",
    "\n",
    "out = NeuralNet(12, 34, 44)\n",
    "print(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f9c65c5-52c4-4268-90b6-0bd58769718d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 5., 8., 9.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "model = FeedForwardNN(10, 32, 43)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4190352e-f599-4ffa-a8c1-5d2baf6f1063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ForwardNet(\n",
      "  (layer1): Linear(in_features=30, out_features=24, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (layer2): Linear(in_features=24, out_features=22, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ForwardNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x =self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "model = ForwardNet(30, 24, 22)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e62f8bb-fe19-4182-8981-dec6c3175439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "ForwardNet(\n",
      "  (layer1): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (layer2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n",
      "epoch 1 / 4, step100 / 600 ,loss = 0.4223\n",
      "epoch 1 / 4, step200 / 600 ,loss = 0.3420\n",
      "epoch 1 / 4, step300 / 600 ,loss = 0.1630\n",
      "epoch 1 / 4, step400 / 600 ,loss = 0.1414\n",
      "epoch 1 / 4, step500 / 600 ,loss = 0.1455\n",
      "epoch 1 / 4, step600 / 600 ,loss = 0.1263\n",
      "epoch 2 / 4, step100 / 600 ,loss = 0.2311\n",
      "epoch 2 / 4, step200 / 600 ,loss = 0.1370\n",
      "epoch 2 / 4, step300 / 600 ,loss = 0.0551\n",
      "epoch 2 / 4, step400 / 600 ,loss = 0.1235\n",
      "epoch 2 / 4, step500 / 600 ,loss = 0.1797\n",
      "epoch 2 / 4, step600 / 600 ,loss = 0.2001\n",
      "epoch 3 / 4, step100 / 600 ,loss = 0.2200\n",
      "epoch 3 / 4, step200 / 600 ,loss = 0.1322\n",
      "epoch 3 / 4, step300 / 600 ,loss = 0.1252\n",
      "epoch 3 / 4, step400 / 600 ,loss = 0.1309\n",
      "epoch 3 / 4, step500 / 600 ,loss = 0.0747\n",
      "epoch 3 / 4, step600 / 600 ,loss = 0.2568\n",
      "epoch 4 / 4, step100 / 600 ,loss = 0.0616\n",
      "epoch 4 / 4, step200 / 600 ,loss = 0.0186\n",
      "epoch 4 / 4, step300 / 600 ,loss = 0.1919\n",
      "epoch 4 / 4, step400 / 600 ,loss = 0.0878\n",
      "epoch 4 / 4, step500 / 600 ,loss = 0.0445\n",
      "epoch 4 / 4, step600 / 600 ,loss = 0.1996\n",
      "accuracy = 10.35\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    " \n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 100\n",
    "n_epochs = 4\n",
    "learning_rate = 0.003\n",
    "input_size = 784\n",
    "hidden_size = 100\n",
    "output_size  = 10\n",
    "\n",
    "# mnist\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root ='./data', train = True, transform = transforms.ToTensor(), download = True)\n",
    "test_dataset  = torchvision.datasets.MNIST(root = './data', train = False, transform = transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size,shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "examples = iter(train_loader)\n",
    "samples, labels = next(examples)\n",
    "print(samples.shape, labels.shape)\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3, i + 1)\n",
    "    plt.imshow(samples[i][0],cmap = 'gray')\n",
    "    \n",
    "#plt.show()\n",
    "img_grid = torchvision.utils.make_grid(samples)\n",
    "\n",
    "class ForwardNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = ForwardNet(input_size, hidden_size, output_size)\n",
    "print(model)\n",
    "        \n",
    "\n",
    "# loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# training_loops\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        labels = labels\n",
    "\n",
    "\n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        l = loss(outputs, labels)\n",
    "        optim = optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"epoch {epoch + 1} / {n_epochs}, step{i +1} / {n_total_steps} ,loss = {l.item():.4f}\")\n",
    "\n",
    "# test\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in (test_loader):\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        labels = labels\n",
    "        output = model(images)\n",
    "# Value, index\n",
    "        \n",
    "        _, prediction = torch.max(outputs, 1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (prediction == labels).sum().item()\n",
    "\n",
    "    acc = 100 * n_correct/ n_samples\n",
    "    print(f\"accuracy = {acc}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f71d80eb-a967-4c9c-88e5-45331428dad8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ')' does not match opening parenthesis '[' on line 18 (2501101181.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[20], line 19\u001b[1;36m\u001b[0m\n\u001b[1;33m    transforms.Normalize((0.5, 0.5,0.5, 0.5), (0.5, 0.5, 0.5)))\u001b[0m\n\u001b[1;37m                                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m closing parenthesis ')' does not match opening parenthesis '[' on line 18\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 100\n",
    "n_epochs = 4\n",
    "learning_rate = 0.003\n",
    "input_size = 784\n",
    "hidden_size = 100\n",
    "output_size  = 10\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5,0.5, 0.5), (0.5, 0.5, 0.5)))\n",
    "\n",
    "# mnist\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root ='./data', train = True, transform = transform, download = True)\n",
    "test_dataset  = torchvision.datasets.CIFAR10(root = './data', train = False, transform = transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size,shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "classes = (\"planes\", \"car\", \"bird\", \"cat\",\n",
    "           \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "145b058c-bc8b-4f31-adca-67a852486456",
   "metadata": {},
   "outputs": [],
   "source": [
    " import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.Wx = nn.Linear(input_size, hidden_size)\n",
    "        self.Wh = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Wy = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.zeros(x.size(1), self.hidden_size)\n",
    "        outputs = []\n",
    "        for t in range(x.size(0)):\n",
    "            h = torch.tanh(self.Wx(x[t]) + self.Wh(h))\n",
    "            y = self.Wy(h)\n",
    "            outputs.append(y)\n",
    "        return torch.stack(outputs), h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a386474d-af7b-45f1-b1e2-2cdbd9591ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.forget = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.input_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.cell_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.output_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.zeros(x.size(1), self.hidden_size)\n",
    "        c = torch.zeros(x.size(1), self.hidden_size)\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        for t in range(x.size(0)):\n",
    "            combined = torch.cat((h, x[t]), dim=1)\n",
    "\n",
    "            f = torch.sigmoid(self.forget(combined))\n",
    "            i = torch.sigmoid(self.input_gate(combined))\n",
    "            g = torch.tanh(self.cell_gate(combined))\n",
    "            o = torch.sigmoid(self.output_gate(combined))\n",
    "\n",
    "            c = f * c + i * g\n",
    "            h = o * torch.tanh(c)\n",
    "\n",
    "            outputs.append(h)\n",
    "\n",
    "        return torch.stack(outputs), (h, c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6807bb1d-0e17-4823-8ff2-fabf8a9be7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.z = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.r = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.h_hat = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.zeros(x.size(1), self.hidden_size)\n",
    "        outputs = []\n",
    "\n",
    "        for t in range(x.size(0)):\n",
    "            combined = torch.cat((x[t], h), dim=1)\n",
    "\n",
    "            z_t = torch.sigmoid(self.z(combined))\n",
    "            r_t = torch.sigmoid(self.r(combined))\n",
    "\n",
    "            combined_reset = torch.cat((x[t], r_t * h), dim=1)\n",
    "            h_tilde = torch.tanh(self.h_hat(combined_reset))\n",
    "\n",
    "            h = (1 - z_t) * h + z_t * h_tilde\n",
    "            outputs.append(h)\n",
    "\n",
    "        return torch.stack(outputs), h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b72951-bcc0-4696-a338-a53227ad8de4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
