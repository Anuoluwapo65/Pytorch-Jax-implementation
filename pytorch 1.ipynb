{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3776ea6c-b2d2-433a-af1b-7b2ba12ba76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%matplotlib_inline` not found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "from glob import glob\n",
    "\n",
    "#import matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib_inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "\n",
    "# import torch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.datasets import datasets\n",
    "from torch.utils.datasets import transforms\n",
    "from matplotlib_colors import _rgba\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "884a9ac4-823e-41ec-86dc-f1cfbce2fa79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66481f65-6db1-4cc2-9cd4-3e2d2af97bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e37e222d50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22cd9cfb-044b-424d-a8dc-2fb4d15b3897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f95e104-536d-4752-93de-8f3959f8f85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3, 7, 8)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86cd2e3b-dbda-49d7-a379-85eaa45a7638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], size=(3, 9, 0))\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(3, 9, 0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b756092f-21e4-42d0-b9b9-08fe127a9998",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.6398e-30, 1.8035e-42, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(4, 8, 9)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1981382b-4ad3-44fe-8890-d1a5b1bc48ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3, 9, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7c73178-d62b-46b1-b195-43c4091a6a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.8695e-01, 9.6133e-01, 6.8345e-01, 8.9880e-01, 5.0508e-02,\n",
      "          5.5546e-01, 7.8613e-01, 5.6623e-02, 7.8419e-01],\n",
      "         [1.4798e-01, 3.8841e-02, 1.0374e-01, 4.2163e-01, 2.3734e-01,\n",
      "          8.1106e-01, 5.3401e-01, 6.8338e-01, 6.5282e-01],\n",
      "         [6.1227e-01, 9.8335e-01, 1.8260e-01, 1.2392e-01, 4.2622e-01,\n",
      "          9.7167e-01, 6.2475e-01, 7.8219e-01, 4.0979e-01],\n",
      "         [3.4706e-01, 2.8339e-01, 7.5210e-01, 3.6280e-01, 6.2434e-01,\n",
      "          8.5685e-01, 7.9121e-01, 3.0541e-01, 3.7614e-02],\n",
      "         [7.7591e-01, 3.1586e-01, 1.5996e-01, 5.8378e-01, 4.8312e-01,\n",
      "          1.1204e-01, 7.8999e-01, 1.8129e-01, 1.0043e-01],\n",
      "         [1.6550e-01, 5.0939e-01, 5.7926e-01, 1.4609e-01, 6.6261e-01,\n",
      "          3.2352e-01, 3.4021e-01, 6.3160e-01, 6.5374e-01],\n",
      "         [8.2440e-02, 8.9604e-01, 3.2628e-01, 5.3052e-01, 5.7340e-01,\n",
      "          8.3325e-01, 8.3110e-01, 7.4649e-01, 3.0476e-01],\n",
      "         [2.4190e-01, 8.5705e-01, 3.4584e-01, 1.3889e-01, 7.6845e-01,\n",
      "          2.2834e-01, 4.8268e-01, 7.7881e-03, 7.5754e-01]],\n",
      "\n",
      "        [[1.8093e-01, 6.8163e-01, 7.0277e-01, 9.2326e-01, 4.9925e-01,\n",
      "          6.0317e-01, 2.2178e-01, 3.9294e-01, 1.9122e-02],\n",
      "         [6.0077e-01, 3.7893e-01, 7.9298e-01, 3.9301e-01, 8.2248e-01,\n",
      "          6.2663e-01, 1.5888e-01, 9.9567e-02, 1.3663e-01],\n",
      "         [1.2403e-01, 5.1739e-01, 8.8906e-01, 1.1054e-01, 2.1466e-01,\n",
      "          5.5461e-01, 1.0248e-01, 3.1253e-01, 1.3620e-01],\n",
      "         [8.3792e-01, 9.1709e-02, 3.3878e-01, 7.4706e-02, 3.0024e-01,\n",
      "          1.0316e-01, 1.7030e-02, 5.8111e-01, 3.4123e-01],\n",
      "         [2.9453e-01, 3.6355e-01, 3.3696e-01, 1.3472e-01, 9.1336e-01,\n",
      "          2.5883e-01, 7.7162e-01, 4.6659e-01, 7.0493e-03],\n",
      "         [5.1356e-01, 4.2811e-01, 8.6880e-01, 6.3178e-01, 5.5118e-01,\n",
      "          1.5457e-02, 7.1842e-01, 5.8303e-01, 9.9724e-01],\n",
      "         [2.6840e-01, 9.4931e-01, 3.4717e-01, 2.8330e-01, 8.9312e-01,\n",
      "          7.0001e-01, 6.2907e-02, 9.7559e-01, 8.7518e-01],\n",
      "         [3.7890e-01, 8.8910e-01, 4.3167e-01, 2.6103e-01, 4.1730e-01,\n",
      "          8.9137e-01, 6.4199e-01, 6.3935e-01, 5.2270e-01]],\n",
      "\n",
      "        [[2.3226e-01, 1.8032e-01, 2.8738e-01, 2.8794e-01, 5.7804e-02,\n",
      "          1.3751e-02, 8.2757e-01, 1.7833e-01, 7.1799e-01],\n",
      "         [8.9436e-01, 6.7859e-01, 3.1358e-01, 9.1470e-02, 6.9024e-01,\n",
      "          9.5038e-01, 7.8154e-01, 4.4344e-01, 4.8443e-01],\n",
      "         [8.0492e-01, 7.5483e-01, 9.8176e-01, 5.9988e-01, 7.2906e-01,\n",
      "          4.4784e-01, 9.0641e-01, 9.2089e-05, 3.7807e-01],\n",
      "         [7.6371e-01, 8.6470e-01, 9.8937e-01, 4.7589e-02, 8.1430e-01,\n",
      "          6.7386e-01, 9.1358e-01, 3.0820e-01, 7.6322e-01],\n",
      "         [2.8901e-01, 9.4875e-02, 9.4014e-01, 2.9092e-01, 6.8498e-01,\n",
      "          9.1270e-01, 7.3880e-01, 2.7146e-02, 7.2872e-01],\n",
      "         [3.7682e-01, 1.8039e-01, 2.2978e-01, 2.4285e-01, 3.9640e-01,\n",
      "          8.7366e-01, 3.9206e-01, 2.5332e-02, 8.7730e-01],\n",
      "         [1.7081e-01, 8.1442e-01, 7.9870e-02, 3.4176e-01, 2.5843e-01,\n",
      "          4.8476e-01, 1.7234e-01, 9.9456e-02, 9.4090e-01],\n",
      "         [9.9316e-01, 3.7192e-01, 6.9496e-01, 3.5903e-02, 5.9894e-01,\n",
      "          4.4182e-01, 4.0815e-01, 3.9284e-02, 3.6296e-01]],\n",
      "\n",
      "        [[1.5132e-01, 9.6998e-01, 1.8661e-01, 3.5290e-01, 6.5155e-01,\n",
      "          7.3936e-01, 3.3980e-01, 6.2128e-01, 8.0118e-01],\n",
      "         [8.0363e-01, 1.3771e-01, 2.9372e-01, 5.9969e-02, 6.8279e-01,\n",
      "          5.6501e-01, 4.1191e-01, 2.3748e-01, 8.9616e-01],\n",
      "         [9.9464e-01, 8.2504e-01, 4.9539e-01, 2.3803e-01, 2.4699e-01,\n",
      "          4.4793e-01, 1.4681e-02, 1.3482e-01, 4.5672e-01],\n",
      "         [3.3863e-01, 7.9913e-01, 5.5740e-01, 4.6173e-01, 5.9104e-01,\n",
      "          8.1249e-01, 1.9912e-01, 8.1473e-01, 9.6694e-01],\n",
      "         [9.3252e-01, 8.2573e-01, 5.9164e-02, 5.9816e-01, 8.6076e-01,\n",
      "          5.3705e-01, 8.7395e-01, 4.9727e-01, 9.8929e-01],\n",
      "         [1.3985e-01, 7.8140e-01, 2.1170e-01, 3.0807e-01, 3.7701e-01,\n",
      "          8.8736e-01, 3.0601e-01, 7.5737e-01, 5.6498e-03],\n",
      "         [7.2438e-01, 2.9730e-01, 2.5141e-01, 7.7442e-01, 3.0804e-02,\n",
      "          5.4357e-01, 1.1232e-01, 6.5871e-02, 6.9370e-01],\n",
      "         [5.1867e-01, 4.9795e-01, 7.1081e-01, 1.6643e-01, 5.3867e-01,\n",
      "          7.8584e-01, 4.3199e-01, 6.2253e-01, 9.3517e-01]],\n",
      "\n",
      "        [[2.3737e-01, 2.7004e-01, 4.6429e-01, 4.4756e-01, 2.1198e-01,\n",
      "          1.0530e-01, 3.1841e-02, 7.4810e-01, 8.3793e-01],\n",
      "         [4.6001e-01, 9.2659e-01, 2.4513e-01, 3.0752e-01, 8.8959e-01,\n",
      "          4.1319e-01, 6.4871e-01, 8.6112e-01, 3.9814e-02],\n",
      "         [9.9725e-01, 8.8904e-01, 8.2060e-01, 7.9655e-01, 6.7368e-01,\n",
      "          5.6156e-01, 8.9981e-01, 4.6752e-01, 2.3762e-01],\n",
      "         [4.9187e-01, 5.7600e-01, 4.6340e-01, 3.8195e-01, 7.7910e-01,\n",
      "          6.4372e-01, 8.9380e-01, 2.9665e-01, 6.7059e-01],\n",
      "         [1.8359e-01, 7.8166e-01, 9.0523e-01, 3.4676e-01, 3.5068e-01,\n",
      "          6.7825e-01, 7.3387e-01, 7.3148e-01, 9.2369e-01],\n",
      "         [6.9570e-01, 8.3707e-01, 5.2031e-01, 1.3885e-01, 2.5584e-01,\n",
      "          6.9001e-01, 1.3750e-01, 5.0380e-01, 8.3201e-01],\n",
      "         [9.5512e-02, 1.0939e-01, 7.4083e-01, 2.9966e-01, 7.3961e-01,\n",
      "          1.2359e-01, 8.9208e-01, 4.4704e-01, 9.0558e-01],\n",
      "         [1.7590e-01, 1.1114e-01, 4.1075e-01, 4.6931e-01, 6.5404e-01,\n",
      "          5.6349e-01, 7.7815e-02, 8.2863e-01, 4.1249e-01]]])\n"
     ]
    }
   ],
   "source": [
    "u = torch.rand(5, 8, 9)\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ba7ce51-4bc8-4a57-a30c-4586b5408117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(8)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b3a5f10-ff49-4123-bdd8-026e43d7c3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "i = torch.arange(8)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17544902-9716-4462-8c7d-e9025ddc6cab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape torch.Size([5, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "x = u.shape\n",
    "print(\"shape\", u.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cb5fe23-e20c-4534-b497-9e38abcd72da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size torch.Size([5, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "v =  u.size()\n",
    "print(\"size\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dbf176b-7e50-419f-ac0d-40b28ac0b73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3094, 0.6075, 0.8562],\n",
       "         [0.0399, 0.4041, 0.3686],\n",
       "         [0.4704, 0.3168, 0.1663],\n",
       "         [0.2488, 0.6075, 0.4631],\n",
       "         [0.4786, 0.3076, 0.1119],\n",
       "         [0.4304, 0.9634, 0.2369],\n",
       "         [0.2894, 0.1722, 0.0912],\n",
       "         [0.1056, 0.7096, 0.2609]],\n",
       "\n",
       "        [[0.7053, 0.4911, 0.7929],\n",
       "         [0.2301, 0.1367, 0.1564],\n",
       "         [0.7619, 0.5723, 0.4911],\n",
       "         [0.4614, 0.6774, 0.1915],\n",
       "         [0.5507, 0.7793, 0.3747],\n",
       "         [0.1483, 0.6539, 0.6452],\n",
       "         [0.7916, 0.7610, 0.9121],\n",
       "         [0.3661, 0.4697, 0.2300]],\n",
       "\n",
       "        [[0.0919, 0.4194, 0.1557],\n",
       "         [0.6062, 0.9720, 0.1754],\n",
       "         [0.6462, 0.4874, 0.2707],\n",
       "         [0.6206, 0.7584, 0.9558],\n",
       "         [0.6159, 0.2043, 0.4921],\n",
       "         [0.5812, 0.8287, 0.1333],\n",
       "         [0.7035, 0.4565, 0.8788],\n",
       "         [0.2918, 0.5051, 0.6804]],\n",
       "\n",
       "        [[0.3380, 0.0614, 0.4854],\n",
       "         [0.3306, 0.4069, 0.8966],\n",
       "         [0.0545, 0.4287, 0.3115],\n",
       "         [0.3106, 0.1970, 0.8973],\n",
       "         [0.9622, 0.4714, 0.0574],\n",
       "         [0.5240, 0.9597, 0.7233],\n",
       "         [0.3592, 0.4503, 0.4376],\n",
       "         [0.5505, 0.7860, 0.4065]],\n",
       "\n",
       "        [[0.8511, 0.9094, 0.4079],\n",
       "         [0.1973, 0.4534, 0.6486],\n",
       "         [0.9077, 0.9110, 0.2997],\n",
       "         [0.9159, 0.5950, 0.5831],\n",
       "         [0.3255, 0.0305, 0.8391],\n",
       "         [0.8155, 0.1815, 0.1551],\n",
       "         [0.4583, 0.5503, 0.7047],\n",
       "         [0.7374, 0.9502, 0.6236]],\n",
       "\n",
       "        [[0.0458, 0.5091, 0.2953],\n",
       "         [0.0556, 0.9667, 0.3280],\n",
       "         [0.7470, 0.8041, 0.6623],\n",
       "         [0.7550, 0.6450, 0.6476],\n",
       "         [0.6801, 0.8135, 0.7036],\n",
       "         [0.8653, 0.5222, 0.6173],\n",
       "         [0.0329, 0.5758, 0.7875],\n",
       "         [0.6437, 0.9984, 0.2525]],\n",
       "\n",
       "        [[0.4214, 0.8941, 0.5095],\n",
       "         [0.2489, 0.0476, 0.3191],\n",
       "         [0.3510, 0.1581, 0.2122],\n",
       "         [0.9447, 0.1393, 0.0197],\n",
       "         [0.3758, 0.4007, 0.1148],\n",
       "         [0.0743, 0.0082, 0.7092],\n",
       "         [0.2099, 0.2896, 0.4013],\n",
       "         [0.4314, 0.3008, 0.7857]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.rand(7, 8, 3)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7b3f531-1ed3-4e55-a783-a54732a76363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size torch.Size([7, 8, 3])\n"
     ]
    }
   ],
   "source": [
    "c = w.size()\n",
    "print(\"size\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5090d0b5-6c90-434e-a5df-d725a7d068ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape torch.Size([7, 8, 3])\n"
     ]
    }
   ],
   "source": [
    "c = w.shape\n",
    "print(\"shape\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24f4908a-c9d0-406d-903e-d4be44d0e0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 7]\n",
      " [7 9]]\n",
      "tensor([[3, 7],\n",
      "        [7, 9]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "bit = np.array([[3,7], [7,9]])\n",
    "print(bit)\n",
    "sit = torch.from_numpy(bit)\n",
    "print(sit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54707787-f74c-4528-9704-48bb28253931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[5, 8],\n",
      "         [4, 0],\n",
      "         [2, 8]]])\n"
     ]
    }
   ],
   "source": [
    "b = np.array([[[5,8], [4,0], [2,8]]])\n",
    "u = torch.from_numpy(b)\n",
    "print(u) ## converting numpy to a torch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad7bc284-9b41-4215-a122-1ea0c2804d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "w = torch.arange(8)\n",
    "v = w.numpy()\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5af8e40-6909-4d88-a287-e08b799f4ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "b = torch.arange(7)\n",
    "c = b.numpy()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7facce22-6ffd-4ce2-9764-dd1e6db37b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 9, 0, 4])\n"
     ]
    }
   ],
   "source": [
    "f = np.array([3, 9, 0, 4])\n",
    "u = torch.from_numpy(f)\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3945443b-dfc0-43bf-9255-d2beee5b8dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7,  8, 15, 14])\n"
     ]
    }
   ],
   "source": [
    "## operations in numpy\n",
    "x = torch.tensor([4,6,9,5])\n",
    "y = torch.tensor([3,2,6,9])\n",
    "\n",
    "w = x + y\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d71b32f8-37bc-41f8-8c18-b5443eb3ceb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.add(3,4)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0665f32e-f123-49fe-b7ed-6b1a42eef1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 14, 12])\n"
     ]
    }
   ],
   "source": [
    "u = torch.tensor([5,6,9])\n",
    "y = torch.tensor([5,8,3])\n",
    "\n",
    "h = u + y\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bfeb283-4ceb-4c2f-8833-b7a426c2f77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = torch.add(4,5)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20a79a87-6097-4156-b9f9-c7622971389a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.sub(6,7)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9280d57-d70e-48ad-a40c-e1492b1e5377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = torch.sub(9,4)\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51d9ea04-6ded-4347-b16d-12fddfc19214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s before tensor([[ 7, 15],\n",
      "        [ 6, 12]])\n",
      "u after the value tensor([[4, 9],\n",
      "        [2, 4]])\n"
     ]
    }
   ],
   "source": [
    "u = torch.tensor([[3,6], [4, 8]])\n",
    "v = torch.tensor([[4,9], [2, 4]])\n",
    "\n",
    "s = v + u\n",
    "print(\"s before\", s)\n",
    "\n",
    "u.add_(v)\n",
    "print(\"u after the value\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdef88dd-6c80-4195-b7f2-4ef598f2cb31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4, 8, 9],\n",
       "         [3, 0, 8],\n",
       "         [3, 8, 7]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.tensor([[[4, 8, 9], [3, 0, 8], [3, 8, 7]]])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "084ccdd4-2aa9-4325-b612-09a676f9f29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1903, 0.6903, 0.5634, 1.2376, 0.8952, 1.0030, 1.8961, 0.8896],\n",
      "        [1.3633, 0.3895, 1.2584, 1.2516, 0.9177, 0.8382, 0.2206, 1.1689],\n",
      "        [1.3421, 1.4666, 0.5974, 0.7897, 0.4270, 0.9850, 1.3147, 0.5055],\n",
      "        [0.9045, 1.3342, 1.0755, 1.6828, 1.2247, 0.5098, 1.2006, 0.3646],\n",
      "        [1.4721, 0.6023, 1.1542, 1.2935, 1.6566, 1.3171, 1.1050, 0.8157],\n",
      "        [1.6635, 0.8927, 1.8562, 0.7718, 0.7430, 1.1774, 0.8087, 1.7715],\n",
      "        [0.1212, 1.1007, 0.4314, 0.9633, 1.0797, 0.5741, 1.7988, 1.4660],\n",
      "        [0.9507, 1.1752, 1.3196, 0.9745, 0.8555, 0.6925, 0.8043, 0.3454]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.rand(8, 8)\n",
    "x = torch.rand(8, 8)\n",
    "\n",
    "c = x + i\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f43f09b-e4e3-48f9-a1a1-dfba724ab82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1903, 0.6903, 0.5634, 1.2376, 0.8952, 1.0030, 1.8961, 0.8896],\n",
       "        [1.3633, 0.3895, 1.2584, 1.2516, 0.9177, 0.8382, 0.2206, 1.1689],\n",
       "        [1.3421, 1.4666, 0.5974, 0.7897, 0.4270, 0.9850, 1.3147, 0.5055],\n",
       "        [0.9045, 1.3342, 1.0755, 1.6828, 1.2247, 0.5098, 1.2006, 0.3646],\n",
       "        [1.4721, 0.6023, 1.1542, 1.2935, 1.6566, 1.3171, 1.1050, 0.8157],\n",
       "        [1.6635, 0.8927, 1.8562, 0.7718, 0.7430, 1.1774, 0.8087, 1.7715],\n",
       "        [0.1212, 1.1007, 0.4314, 0.9633, 1.0797, 0.5741, 1.7988, 1.4660],\n",
       "        [0.9507, 1.1752, 1.3196, 0.9745, 0.8555, 0.6925, 0.8043, 0.3454]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.add_(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a30084d0-71eb-4f8e-b2e0-e482bdfd7d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12, 12,  8, 16])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([3, 9, 0, 7])\n",
    "u = torch.tensor([9, 3, 8, 9])\n",
    "\n",
    "w = i + u\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc8ed130-bec8-48e8-8017-e338cf741023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 12,  8, 16])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.add_(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fa48716-018f-4a9c-b146-5e80b6a158e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1ee7a03-9513-48dc-8d25-f5eebbb6a142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x  = x.view(2,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a823b7ef-9b15-4c7b-a041-5e9a5f2507c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(9)\n",
    "print(x)\n",
    "x = x.view(3,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4d26af8-2826-437c-a293-a16e8c52cec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5],\n",
       "        [6, 7]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(8)\n",
    "x = x.view(4, 2)\n",
    "x               ## view is use for changing shape or reshaping values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2095f77-fe40-4a29-bf74-6291d14b152b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 4, 6],\n",
       "        [1, 3, 5, 7]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.permute(1,0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e1f8c58-fd56-44d1-8247-6693a85dc7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 4, 6],\n",
       "        [1, 3, 5, 7]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.permute(0, 1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d547c8d-72b0-4464-8622-d8401fb56ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.arange(9).view(3,3)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce1e84a2-b648-41c0-9ab7-b53737c2309a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "g = torch.arange(10).view(2, 5)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7cafae21-e4e7-4690-bed6-241e4c9f53aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5]])\n"
     ]
    }
   ],
   "source": [
    "c = torch.arange(6).view(3, 2)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be6270ca-aed5-499f-9d1d-8311937fd3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.arange(6).view(2,3)\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5a13ce1-8732-48a7-b51e-59eeac86e6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.arange(9).view(3,3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e69296f4-d5c7-421a-9b67-81a1b2dab83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15, 18, 21],\n",
       "        [42, 54, 66]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = u @ y\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "26523e6a-af3c-4654-af7d-27f62f0ccead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15, 18, 21],\n",
       "        [42, 54, 66]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.matmul(u, y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "32ab439b-5a54-4cc2-b31e-5eb20f472d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## indexing in pytoch\n",
    "x = torch.arange(10).view(2, 5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "badaab87-b381-43f3-84db-09e4bcb99d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 7])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x[:, 2]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1f576eef-e7e4-48a0-a033-52eb992e5a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.arange(6).view(2, 3)\n",
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1709e47-ceb7-47e5-859f-da40ad8888c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 5])\n"
     ]
    }
   ],
   "source": [
    "print(d[0:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee3a23db-0e7d-4173-8df2-e4d52a2bb34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4])\n"
     ]
    }
   ],
   "source": [
    "print(d[1:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "03fe7e2b-6919-4219-b1e5-af39fd0e4134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(9)\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d5700cb1-4b63-4515-9ae0-d9b5da61f011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "u = torch.zeros(7)\n",
    "print(u.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a742849a-188e-488e-bee7-1b1710dfa8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "x.requires_grad_(True)\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0596a8ac-c3d2-46f0-8928-e07c3a3de88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "u.requires_grad_(True)\n",
    "print(u.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8e1807ca-da4c-4399-8f8b-fead9a87247e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(3, requires_grad = True, dtype = torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3f18918-8c63-4339-a023-b92ffe6d7790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y tensor(12., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = x + 2\n",
    "b = a ** 2\n",
    "c = b + 3\n",
    "y = c.mean()\n",
    "print(\"Y\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "95a77897-4d77-4b7a-9168-75cf986644a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5.], requires_grad=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.arange(6, requires_grad = True, dtype = torch.float32)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3fd6b8a1-c5c0-4949-93d8-08e3c4d0ff31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y tensor(27.1667, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = v + 2\n",
    "b = a ** 2\n",
    "c = b + 4\n",
    "y = c.mean()\n",
    "print(\"Y\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0d813111-ef2a-494f-887b-c1edba780db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fad494c3-145e-43db-b438-665ab77e396d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6667, 1.0000, 1.3333, 1.6667, 2.0000, 2.3333])\n"
     ]
    }
   ],
   "source": [
    "print(v.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a3d0a805-4600-4c06-bb6b-bad108f9d8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e85baecc-be3c-4079-8535-c8147184f800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is the gpu_available? False\n"
     ]
    }
   ],
   "source": [
    "gpu_avail = torch.cuda.is_available()\n",
    "print(f\"is the gpu_available? {gpu_avail}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ee25a6d6-34a3-43ff-8568-d26929d675b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available()else torch.device(\"cpu\")\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f994ba87-0a10-434f-963e-fe41eefd4219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available()else torch.device(\"cpu\")\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "33b98a1b-b198-4540-9e2f-9f4b25f15bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor([0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(7)\n",
    "x = x.to(device)\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1cc5cc10-34cc-4acc-8696-d3c42d90e1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available()else torch.device(\"cpu\")\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0c5e17ad-d721-4798-bf22-98b95000c8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "y = torch.zeros(8)\n",
    "x = y.to(device)\n",
    "print(\"x\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d119f8c2-0750-4929-8a97-9e761260c17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu time :0.00221s\n",
      "CPU time: 0.00221s\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(500, 500)\n",
    "start_time = time.time()\n",
    "_ = torch.matmul(x, x)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"cpu time :{(end_time - start_time):6.5f}s\")\n",
    "print(f\"CPU time: {(end_time - start_time):6.5f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c94998af-e258-4c77-b3c7-eaa5e51101b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu time :0.00042s\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(12,12)\n",
    "start_time = time.time()\n",
    "_ = torch.matmul(x, x)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"cpu time :{(end_time - start_time):6.5f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "026c5130-db84-447f-a242-935222d07d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cpu time is 0.00115s\n"
     ]
    }
   ],
   "source": [
    "v = torch.ones(400, 400)\n",
    "start_time = time.time()\n",
    "_ = torch.matmul(v,v)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"the cpu time is {(end_time - start_time):6.5f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "065203dc-d488-4e9f-9fd9-9570a6447133",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, maia, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m _ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(x, x)\n\u001b[0;32m      4\u001b[0m start  \u001b[38;5;241m=\u001b[39m start\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mEvent(starting_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, maia, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: device"
     ]
    }
   ],
   "source": [
    "x = x.to(\"device\")\n",
    "_ = torch.matmul(x, x)\n",
    "\n",
    "start  = start.cuda.Event(starting_time = True)\n",
    "end    = end.cuda.Event(ending_time = True)\n",
    "\n",
    "start_record()\n",
    "_ = torch.matmul(x, x)\n",
    "\n",
    "end_record()\n",
    "\n",
    "print(f\" the gpu :{(0.0001 * start_elpased_time(end)):6.5f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d9713117-4bea-4388-a382-bf39bc870fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ac50b8bd-4c5c-4e07-8e67-78e96e857b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(self, num_input, hidden_layer, num_output):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(num_input, hidden_layer)\n",
    "        self.act_fn = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(hidden_layer, num_output)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bf01f383-c2ce-40db-9166-3e76e16ad61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module MyModule(\n",
      "  (linear1): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (act_fn): Tanh()\n",
      "  (linear2): Linear(in_features=4, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "module = MyModule(num_input = 3, hidden_layer = 4, num_output = 5)\n",
    "print(\"module\", module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0b73a561-faf7-4747-8dd8-bc47331fae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mymodules(nn.Module):\n",
    "    def __init__(self, num_input, num_hidden, num_output):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(num_input, num_hidden)\n",
    "        self.activate = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(num_hidden, num_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activate(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "33a19a01-1891-45b7-8a57-dad0a2c198e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module Mymodules(\n",
      "  (linear1): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (activate): Tanh()\n",
      "  (linear2): Linear(in_features=4, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "module = Mymodules(num_input = 3, num_hidden = 4, num_output = 7)\n",
    "print(\"module\", module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8d7b2ca0-6777-47c5-a93f-879e4c13763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9b32133e-140f-4734-b719-6c0ee4cc6289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " parameters linear1.weight, shape torch.Size([4, 3]) \n",
      " parameters linear1.bias, shape torch.Size([4]) \n",
      " parameters linear2.weight, shape torch.Size([7, 4]) \n",
      " parameters linear2.bias, shape torch.Size([7]) \n"
     ]
    }
   ],
   "source": [
    "for name, params in module.named_parameters():\n",
    "    print(f\" parameters {name}, shape {params.shape} \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ba17de62-4a7e-4997-a8fa-abaf90cba2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter linear1.weight, shape torch.Size([4, 3])\n",
      "parameter linear1.bias, shape torch.Size([4])\n",
      "parameter linear2.weight, shape torch.Size([7, 4])\n",
      "parameter linear2.bias, shape torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "for name, params in module.named_parameters():\n",
    "    print(f\"parameter {name}, shape {params.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9e2aaa27-6ba0-4c51-a7fa-b9233d4706d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cbb0f351-acbd-4a2f-ab00-4d8dc14beb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d8831fe4-00fc-45b0-8793-76c776386e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(data.Dataset):\n",
    "    def __init__(self, books, size, std = 0.004):\n",
    "        super().__init__()\n",
    "\n",
    "        self.books = books\n",
    "        self.size = size\n",
    "        self.std = std\n",
    "        self.generate.continous_xor_()\n",
    "\n",
    "\n",
    "    def generate_continous_xor(self):\n",
    "\n",
    "\n",
    "        data = torch.randint(high = 2, low = 0, size = (self.size, 2), dtype = torch.float32)\n",
    "        label = (data.sum(dim=1) ==1).to(torch.long)\n",
    "\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_point = self.data[idx]\n",
    "        data_label = self.label[idx]\n",
    "\n",
    "        return data_point, data_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4821aeb0-dc8c-49c2-861c-7b089c481385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "class IMAGELOADER_FILES(Dataset):\n",
    "    def __init__(self, root_dir, labels, transforms = None):\n",
    "        self.root_dir = root_dir\n",
    "        self.labels = labels\n",
    "        self.image_files = list(labels.keys())\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.image.files\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_files = os.path.join(self.image_files[index], self.root_dir)\n",
    "        image = image.open(image_files). convert(\"RGB\")\n",
    "        label = self.labels[self.image_files[idx]]\n",
    "\n",
    "        return image, label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "30f527ff-44e6-4b7c-8cde-3d9d61382701",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, images, text, tokenizer, transform):\n",
    "        self.images = images\n",
    "        self.text = text\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitems__(self, indx):\n",
    "        images = self.transform(image.open.files(self.images[idx]))\n",
    "        tokenizer = self.tokenizer(\n",
    "            self.text[idx],\n",
    "            paddings = \"max_length\",\n",
    "            truncations = True,\n",
    "            return_tensor = \"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"images\": images,\n",
    "            \"out_put\": tokenizer[\"out_put\"].unsqueeze(0),    \n",
    "            \"attention_map\": tokenizer[\"attention_map\"].unsqueeze(0)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "63d13f09-c35c-438c-b737-b3e63fe71c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom(Dataset):\n",
    "    def __init__(self,images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        labels = self.labels[idx]\n",
    "        images = self.images[idx]\n",
    "\n",
    "        return labels, images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6b442808-ab52-44c2-bfb7-bf903038934b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the customs shapes 200\n",
      "the data points 0 is  (0, 0)\n"
     ]
    }
   ],
   "source": [
    "images = list(range(200))\n",
    "labels = list(range(500))\n",
    "\n",
    "customs = Custom(images = images, labels = labels)\n",
    "print(\"the customs shapes\", len(customs))\n",
    "print(\"the data points 0 is \", customs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "69fbea7e-be0b-40ff-ac1b-37ddf77021a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images shapes torch.Size([40])\n",
      "label shapes torch.Size([40])\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "loader = DataLoader(\n",
    "    customs,\n",
    "    batch_size = 40,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "loader\n",
    "\n",
    "images, labels = next(iter(loader))\n",
    "\n",
    "print(\"images shapes\", images.shape)\n",
    "print(\"label shapes\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0178fe33-98a3-43cb-bcfa-aaa8c86a24c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9911251c-b175-424f-9069-0a4a3cf09809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e68e800f-27a2-4701-b5e0-21913a256d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Category(Dataset):\n",
    "    def __init__(self, root_dir, transform = None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples  = []\n",
    "\n",
    "\n",
    "        for label, images in enumerate([\"cat\", \"dog\"]):\n",
    "            class_path = os.path.join(root_dir, images)\n",
    "        for img_name in os.listdir(class_path):\n",
    "            self.samples.append((os.path.join(class_path, img_name) , label))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name, label = self.samples[index]\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "           image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0d476ccc-82cb-4dac-8a14-8c73b74c6ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7ec9efa5-cc6e-4096-9d6e-c264495022f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'dataset/train\\\\dog'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 11\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m      6\u001b[0m transforms \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m      7\u001b[0m     T\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)),\n\u001b[0;32m      8\u001b[0m     T\u001b[38;5;241m.\u001b[39mToTensor()\n\u001b[0;32m      9\u001b[0m ])\n\u001b[1;32m---> 11\u001b[0m dataset \u001b[38;5;241m=\u001b[39m Category(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset/train\u001b[39m\u001b[38;5;124m\"\u001b[39m, transform\u001b[38;5;241m=\u001b[39mtransforms)\n\u001b[0;32m     12\u001b[0m loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m images, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(loader))\n",
      "Cell \u001b[1;32mIn[102], line 10\u001b[0m, in \u001b[0;36mCategory.__init__\u001b[1;34m(self, root_dir, transform)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label, images \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdog\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m      9\u001b[0m     class_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root_dir, images)\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(class_path):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\u001b[38;5;241m.\u001b[39mappend((os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(class_path, img_name) , label))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'dataset/train\\\\dog'"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "transforms = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = Category(\"dataset/train\", transform=transforms)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "images, label = next(iter(loader))\n",
    "print(images.shape)   # [32, 3, 224, 224]\n",
    "print(label.shape)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1a6e689b-f915-4bc2-be36-5e6db36e2e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCEWithLogitsLoss()"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Loss = nn.BCEWithLogitsLoss()\n",
    "Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7bc7ad05-3179-461d-b01c-7a75a32f436b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCELoss()"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.BCELoss()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f7e148a9-e951-4433-ae5d-cf32c4496a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(module.parameters(), lr = 0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d720b3fd-6f64-4b9c-9a75-cc174d9b543c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.004\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c93742f5-9772-4340-9074-e0b378fb5c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e8aad6ac-894e-4440-9e52-be372237f247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1e307bb3390>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = Custom(labels = labels, images = images)\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = 40,\n",
    "    shuffle = True\n",
    ")\n",
    "train_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cd44b464-c423-4375-855e-0b63810c5a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mymodules(\n",
       "  (linear1): Linear(in_features=3, out_features=4, bias=True)\n",
       "  (activate): Tanh()\n",
       "  (linear2): Linear(in_features=4, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "63d3bd94-4bac-4c53-afc4-ba8f088d9efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BatchSampler', 'ChainDataset', 'ConcatDataset', 'DFIterDataPipe', 'DataChunk', 'DataLoader', 'Dataset', 'DistributedSampler', 'IterDataPipe', 'IterableDataset', 'MapDataPipe', 'RandomSampler', 'Sampler', 'SequentialSampler', 'StackDataset', 'Subset', 'SubsetRandomSampler', 'TensorDataset', 'WeightedRandomSampler', '_DatasetKind', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_utils', 'argument_validation', 'dataloader', 'datapipes', 'dataset', 'default_collate', 'default_convert', 'distributed', 'functional_datapipe', 'get_worker_info', 'graph', 'graph_settings', 'guaranteed_datapipes_determinism', 'non_deterministic', 'random_split', 'runtime_validation', 'runtime_validation_disabled', 'sampler']\n"
     ]
    }
   ],
   "source": [
    "print(dir(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f2275967-e491-44b8-a159-d59df1176561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\ace\\anaconda3\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ace\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ensorflow (C:\\Users\\ACE\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow (C:\\Users\\ACE\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow (C:\\Users\\ACE\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b85a85e5-fbd8-47e1-8338-a0b373c9f1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(module, optimizer, train_dataset, loss, num_epochs = 300):\n",
    "    module.train()\n",
    "\n",
    "\n",
    "    # Training the loop\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        images, labels in loader\n",
    "\n",
    "        data_images = images.to(\"device\").float()\n",
    "        data_labels = labels.to(\"device\").float()\n",
    "\n",
    "    #  step 2: calculating the prediction \n",
    "\n",
    "        preds = module(data_images)\n",
    "        preds = preds.squeeze(dim = 1)\n",
    "\n",
    "   # step 3 : calculating the loss function\n",
    "\n",
    "        loss = Loss(preds, data_labels)\n",
    "\n",
    "  # step 4 : before calculating the gradient descent we have to scale the optimizer value to zero\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "  # step 5 : calculate the backward propagation\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "   # step 6 : update the parameters of those values\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2ca2b547-0915-406d-8824-06a847514f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(module, optimizer, train_dataset, loss_fn, batch_size=32, num_epochs=300):\n",
    "    # Device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    module.to(device)\n",
    "    module.train()\n",
    "    \n",
    "    # Create DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Training Epochs\"):\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            # Move to device\n",
    "            images = images.to(device).float()\n",
    "            labels = labels.to(device).float()\n",
    "\n",
    "            # Step 2: forward pass\n",
    "            preds = module(images)\n",
    "            if preds.shape != labels.shape:\n",
    "                preds = preds.squeeze(dim=1)  # adjust shape if needed\n",
    "\n",
    "            # Step 3: calculate loss\n",
    "            loss = loss_fn(preds, labels)\n",
    "\n",
    "            # Step 4: zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Step 5: backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Step 6: update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        avg_loss = epoch_loss / len(train_loader.dataset)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3300390-2142-443b-b615-fac3b3f5d648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c629b61a-4a47-4ed8-b221-91f71eae6e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dea48b-5d6f-4dd1-b360-ae363b80bec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff1aaed-3ae1-4ae0-82b0-0aa7aa485773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacc2019-f24b-4517-ad34-31736f81c36a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880553c1-6418-45d6-b6b8-387412b3526a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb51848-bf0c-4a0c-b2c8-ed010533e40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a932d00f-db8c-4ea4-a310-2dcb96e8860f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eec7a8e-5001-427f-925e-e84b60056f88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
